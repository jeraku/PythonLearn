RAG - Vector DB 
Data retrieve -> chunk -> augment -> output 

LLM cut off date -> gold rate today. 


Document - Chunks -> embedding model -> vector Db -> 
User -> query -> 

query 
context
Augment
prompt
LLM



Langchain
groqclient

Load PDF 
chunks / split PDF
Vector DB >> FAISS DB and nomic embed text model


